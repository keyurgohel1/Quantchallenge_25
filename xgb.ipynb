{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "98306408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "98a84abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('C:\\\\Users\\\\sword\\\\OneDrive - The University of Melbourne\\\\Desktop\\\\Quantchallenge\\\\Quantchallenge_25\\\\Data\\\\train.csv')\n",
    "df2 = pd.read_csv('C:\\\\Users\\\\sword\\\\OneDrive - The University of Melbourne\\\\Desktop\\\\Quantchallenge\\\\Quantchallenge_25\\\\Data\\\\train_new.csv')\n",
    "merged = pd.concat([df1, df2], axis = 1)\n",
    "new_order = ['time','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Y1', 'Y2']\n",
    "df_train = merged[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de5111e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test = pd.read_csv('C:\\\\Users\\\\sword\\\\OneDrive - The University of Melbourne\\\\Desktop\\\\Quantchallenge\\\\Quantchallenge_25\\\\Data\\\\test.csv')\n",
    "df2_test = pd.read_csv('C:\\\\Users\\\\sword\\\\OneDrive - The University of Melbourne\\\\Desktop\\\\Quantchallenge\\\\Quantchallenge_25\\\\Data\\\\test_new.csv')\n",
    "merged_test = pd.concat([df1_test, df2_test], axis = 1)\n",
    "new_order_test = ['time','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "df_test = merged_test[new_order_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7a53a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_cols = ['A', 'B', 'D', 'F', 'I', 'K', 'L', 'O']\n",
    "g2_cols = ['C', 'E', 'G', 'H', 'J', 'M', 'N', 'P']\n",
    "FEATURE_COLS = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cc8942f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "robust_scaler = RobustScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4020b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['time'])\n",
    "df_train.interpolate(method='linear', inplace=True)\n",
    "df_train['P'] = (df_train['P']>0.5).astype(int)\n",
    "df_train[g1_cols] = pt.fit_transform(df_train[g1_cols])\n",
    "df_train[g2_cols] = robust_scaler.fit_transform(df_train[g2_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ba7bd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r2(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred)**2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "    if ss_tot == 0:\n",
    "        return 1.0 if np.allclose(y_true, y_pred) else 0.0\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def mean_r2_multi(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    n_targets = y_true.shape[1]\n",
    "    r2s = []\n",
    "    for t in range(n_targets):\n",
    "        r2s.append(calculate_r2(y_true[:, t], y_pred[:, t]))\n",
    "    return float(np.mean(r2s))\n",
    "\n",
    "multi_r2_scorer = make_scorer(lambda yt, yp: mean_r2_multi(yt, yp), greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ad77ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=['time'])\n",
    "df_test.interpolate(method='linear', inplace=True)\n",
    "df_test['P'] = (df_test['P']>0.5).astype(int)\n",
    "df_test[g1_cols] = pt.transform(df_test[g1_cols])\n",
    "df_test[g2_cols] = robust_scaler.transform(df_test[g2_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "30a8d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_g1 = df_train[g1_cols].values\n",
    "X_g2 = df_train[g2_cols].values\n",
    "y = np.vstack([df_train['Y1'].values, df_train['Y2'].values]).T\n",
    "\n",
    "X_test_g1 = df_test[g1_cols].values\n",
    "X_test_g2 = df_test[g2_cols].values\n",
    "\n",
    "if 'id' in df_test.columns:\n",
    "    test_ids = df_test['id'].astype(str).values\n",
    "else:\n",
    "    test_ids = df_test.index.astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "727e7054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model G1 (g1_cols) ...\n",
      "Fitting 4 folds for each of 32 candidates, totalling 128 fits\n",
      "G1 best params: {'estimator__colsample_bytree': 0.7, 'estimator__learning_rate': 0.05, 'estimator__max_depth': 5, 'estimator__n_estimators': 100, 'estimator__subsample': 1.0}\n",
      "Fitting Model G2 (g2_cols) ...\n",
      "Fitting 4 folds for each of 32 candidates, totalling 128 fits\n",
      "G2 best params: {'estimator__colsample_bytree': 0.7, 'estimator__learning_rate': 0.05, 'estimator__max_depth': 3, 'estimator__n_estimators': 300, 'estimator__subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "Xg1_tr, Xg1_val, Xg2_tr, Xg2_val, y_tr, y_val = train_test_split(\n",
    "    X_g1, X_g2, y, test_size=0.15, random_state=42\n",
    ")\n",
    "base_xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=1, verbosity=0)\n",
    "multi_base = MultiOutputRegressor(base_xgb, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [100, 300],\n",
    "    'estimator__max_depth': [3, 5],\n",
    "    'estimator__learning_rate': [0.05, 0.1],\n",
    "    'estimator__subsample': [0.7, 1.0],\n",
    "    'estimator__colsample_bytree': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(\n",
    "    estimator=multi_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=multi_r2_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print(\"Fitting Model G1 (g1_cols) ...\")\n",
    "grid.fit(Xg1_tr, y_tr)\n",
    "best_model_g1 = grid.best_estimator_\n",
    "print(\"G1 best params:\", grid.best_params_)\n",
    "\n",
    "print(\"Fitting Model G2 (g2_cols) ...\")\n",
    "grid2 = GridSearchCV(\n",
    "    estimator=MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=1, verbosity=0),\n",
    "                                   n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    scoring=multi_r2_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "grid2.fit(Xg2_tr, y_tr)\n",
    "best_model_g2 = grid2.best_estimator_\n",
    "print(\"G2 best params:\", grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5dafc712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 validation R2s: Y1=0.04522, Y2=0.69598, mean=0.37060\n",
      "G2 validation R2s: Y1=0.77454, Y2=0.38238, mean=0.57846\n",
      "Ensemble weights -> G1: 0.390, G2: 0.610\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_g1 = best_model_g1.predict(Xg1_val)\n",
    "y_val_pred_g2 = best_model_g2.predict(Xg2_val)\n",
    "\n",
    "# compute per-target R2s\n",
    "r2_y1_g1 = calculate_r2(y_val[:,0], y_val_pred_g1[:,0])\n",
    "r2_y2_g1 = calculate_r2(y_val[:,1], y_val_pred_g1[:,1])\n",
    "mean_r2_g1 = np.mean([r2_y1_g1, r2_y2_g1])\n",
    "\n",
    "r2_y1_g2 = calculate_r2(y_val[:,0], y_val_pred_g2[:,0])\n",
    "r2_y2_g2 = calculate_r2(y_val[:,1], y_val_pred_g2[:,1])\n",
    "mean_r2_g2 = np.mean([r2_y1_g2, r2_y2_g2])\n",
    "\n",
    "print(f\"G1 validation R2s: Y1={r2_y1_g1:.5f}, Y2={r2_y2_g1:.5f}, mean={mean_r2_g1:.5f}\")\n",
    "print(f\"G2 validation R2s: Y1={r2_y1_g2:.5f}, Y2={r2_y2_g2:.5f}, mean={mean_r2_g2:.5f}\")\n",
    "\n",
    "score_g1 = max(mean_r2_g1, 0.0)\n",
    "score_g2 = max(mean_r2_g2, 0.0)\n",
    "if score_g1 + score_g2 == 0:\n",
    "    w1, w2 = 0.5, 0.5\n",
    "else:\n",
    "    w1 = score_g1 / (score_g1 + score_g2)\n",
    "    w2 = score_g2 / (score_g1 + score_g2)\n",
    "\n",
    "print(f\"Ensemble weights -> G1: {w1:.3f}, G2: {w2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ac5130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_g1_test = best_model_g1.predict(X_test_g1)\n",
    "pred_g2_test = best_model_g2.predict(X_test_g2)\n",
    "y_test_ensemble = w1 * pred_g1_test + w2 * pred_g2_test\n",
    "\n",
    "if np.isnan(y_test_ensemble).any():\n",
    "    print(\"Warning: NaNs found in ensemble predictions; filling with train target means.\")\n",
    "    y_mean = np.nanmean(y, axis=0)\n",
    "    for col in range(y_test_ensemble.shape[1]):\n",
    "        col_nan = np.isnan(y_test_ensemble[:, col])\n",
    "        if np.any(col_nan):\n",
    "            y_test_ensemble[col_nan, col] = y_mean[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6c9ab26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Y1': y_test_ensemble[:, 0],\n",
    "    'Y2': y_test_ensemble[:, 1]\n",
    "})\n",
    "assert not out_df[['Y1','Y2']].isnull().any().any(), \"Predictions contain NaNs!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "293141d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions to predictions_ensemble_g1g2.csv (size MB: 0.452)\n"
     ]
    }
   ],
   "source": [
    "output_path = 'predictions_ensemble_g1g2.csv'\n",
    "out_df.to_csv(output_path, index=False, float_format='%.8f')\n",
    "print(f\"Wrote predictions to {output_path} (size MB: {os.path.getsize(output_path)/1024**2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d2f3d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Validation mean R2s: G1= 0.3706000110695048  G2= 0.5784620931490871\n",
      "Ensemble final weights: (np.float64(0.39049079024669037), np.float64(0.6095092097533096))\n"
     ]
    }
   ],
   "source": [
    "print(\"Done.\")\n",
    "print(\"Validation mean R2s: G1=\", mean_r2_g1, \" G2=\", mean_r2_g2)\n",
    "print(\"Ensemble final weights:\", (w1, w2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantchallenge_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
